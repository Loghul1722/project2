# ENHANCING COMMUNICATION ACCESSIBILITY THROUGH ANIMATED SIGN LANGUAGE

## About
In today's increasingly interconnected world, effective communication is fundamental to building bridges across diverse communities. However, for individuals who are deaf or mute, traditional methods of communication often present significant barriers. The inability to easily access and understand sign language, a vital mode of communication for the deaf and mute community, can lead to feelings of isolation and exclusion.
In response to these challenges, "Animating Inclusivity" presents an innovative approach to enhancing communication accessibility through the power of animation. By leveraging cutting-edge animation technology, this project seeks to transform the way sign language is taught and understood. Instead of relying on static images or written descriptions, animated sign language offers a dynamic and engaging learning experience that is more conducive to effective communication.
At the heart of this project is a commitment to promoting inclusivity and understanding between the deaf and mute community and the broader society. By making sign language more accessible and interactive, "Animating Inclusivity" aims to break down communication barriers and foster greater empathy and connection between individuals of all abilities.
Furthermore, this project recognizes the importance of cultural sensitivity and authenticity in representing sign language. Through collaboration with experts and members of the deaf and mute community, the animated content will be developed with meticulous attention to detail, ensuring that the nuances of expression and meaning are accurately portrayed.


## Features
Animated Sign Language Content Creation: Users can create animated sign language content using intuitive tools within the platform. This feature allows educators, sign language experts, and community members to contribute to the growing library of animated sign language resources.

Interactive Learning Modules: The platform offers interactive learning modules that guide users through various aspects of sign language. These modules include interactive exercises, quizzes, and games to reinforce learning and improve retention.

Personalized Learning Paths: Users can personalize their learning paths based on their proficiency level, learning goals, and interests. The platform tracks users' progress and suggests tailored learning activities to help them achieve their objectives.

Accessibility Features: The platform includes accessibility features such as captioning, audio descriptions, and adjustable playback speed to accommodate users with different needs and preferences. This ensures that the platform is accessible to individuals with visual or hearing impairments.

Community Engagement: Users can engage with a supportive community of learners, educators, and experts through discussion forums, live chat, and collaborative projects. This feature fosters peer support, knowledge sharing, and collaboration among users.

Cultural Sensitivity: The platform emphasizes cultural sensitivity and authenticity in the representation of sign language content. Users can access resources that reflect the linguistic and cultural nuances of different sign languages and communities.

Feedback and Progress Tracking: Users receive feedback on their learning progress and performance through detailed analytics and progress reports. This feature helps users identify areas for improvement and track their growth over time.

Integration with Assistive Technologies: The platform seamlessly integrates with assistive technologies such as screen readers and voice recognition software to enhance accessibility for users with disabilities.

## Requirements
 HARDWARE REQUIREMENTS
1.NVIDIA GeForce GTX 1650 Ti
2.8 GB RAM 
3.11 Gen Intel Core i5 

SOFTWARE REQUIREMENTS 
1.VS Code
2.Python 3.8
3.React JS
## System Architecture
<!--Embed the system architecture diagram as shown below-->

![Screenshot 2024-04-01 220257](https://github.com/Loghul1722/project2/assets/132638997/bfcc5197-c4ec-472b-b9ba-0546263eeabf)



## Output

#### Output

![Screenshot (50)](https://github.com/Loghul1722/project2/assets/132638997/bf54cf5e-c2f3-4c2a-ae61-8305e877755d)

![Screenshot (49)](https://github.com/Loghul1722/project2/assets/132638997/3359094d-5188-4638-9a20-cc70b11b395d)





## Results and Impact
The primary outcome would be improved accessibility for the deaf and mute community. The availability of animated sign language resources and an interactive learning platform would make learning sign language more accessible and engaging for individuals who rely on it for communication.
By providing a more effective and engaging way to learn sign language, the project would empower individuals within the deaf and mute community to communicate more effectively with others. This empowerment can lead to increased confidence, independence, and participation in various aspects of life, including education, employment, and social interactions.

## References
[1]       Rastgoo, Razieh, Kourosh Kiani, Sergio Escalera, and Mohammad Sabokrou. "Sign language production: A review." In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 3451-3461. 2021.

[2]         Kahlon, Navroz Kaur, and Williamjeet Singh. "Machine translation from text to sign language: a systematic review." Universal Access in the Information Society 22, no. 1 (2023): 1-35.

[3]       aunders, Ben, Necati Cihan Camgoz, and Richard Bowden. "Progressive transformers for end-to-end sign language production." In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XI 16, pp. 687-705. Springer International Publishing, 2020.

[4]Rastgoo, Razieh, Kourosh Kiani, Sergio Escalera, Vassilis Athitsos, and Mohammas Sabokrou. "A survey on recent advances in Sign Language Production." Expert Systems with Applications (2023): 122846.

[5]	     Kipp, Michael, Quan Nguyen, Alexis Heloir, and Silke Matthes. "Assessing the deaf user perspective on   sign language avatars." In The proceedings of the 13th international ACM SIGACCESS conference on Computers and accessibility, pp. 107-114. 2011.

[6]	Stoll, Stephanie, Simon Hadfield, and Richard Bowden. "Signsynth: Data-driven sign language video generation." In European Conference on Computer Vision, pp. 353-370. Cham: Springer International Publishing, 2020.
